# ğŸ¤– Reconhecimento de DÃ­gitos MNIST c

Este projeto utiliza uma **Rede Neural**, construÃ­da com TensorFlow/Keras, para reconhecer dÃ­gitos manuscritos (0-9).

O projeto Ã© dividido em duas partes principais:
1.  **`treinar_modelo.py`**: Um script que constrÃ³i, treina e salva o modelo de CNN usando o famoso dataset MNIST.
2.  **`app.py`**: Uma aplicaÃ§Ã£o web interativa, construÃ­da com Gradio, que carrega o modelo treinado e permite que o usuÃ¡rio desenhe um dÃ­gito para obter uma previsÃ£o em tempo real.

### ğŸš€ Link da ApresentaÃ§Ã£o (Canva)

Para mais detalhes sobre o projeto, acesse nossa apresentaÃ§Ã£o no Canva:

[ApresentaÃ§Ã£o do Projeto - Reconhecimento de DÃ­gitos (Canva)](https://www.canva.com/design/DAG3wv1yZcQ/_ud0nIhJC1pNM-TG4jjDdQ/edit?utm_content=DAG3wv1yZcQ&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)

## ğŸ“Š Resultados do Treinamento

O script de treinamento (`treinar_modelo.py`) gera os seguintes grÃ¡ficos de performance, demonstrando um modelo com alta acurÃ¡cia e sem *overfitting*:

![GrÃ¡ficos de AcurÃ¡cia e Perda do Treinamento]([httpsa://i.imgur.com/g880Fq3.png](https://github.com/GabrielBianconiconi/Redes-Neurais_MNIST/blob/main/graficos_treinamento.png))


## ğŸ“‚ Estrutura do Projeto

```
/reconhecimento-digitos-mnist
â”‚
â”œâ”€â”€ ğŸ“œ treinar_modelo.py   # Script para treinar a CNN e salvar o .h5
â”œâ”€â”€ ğŸš€ app.py              # Script para rodar a interface web com Gradio
â”œâ”€â”€ ğŸ§  modelo_mnist.h5     # (Gerado) O modelo treinado
â”œâ”€â”€ ğŸ“Š graficos_treinamento.png # (Gerado) GrÃ¡ficos de performance
â””â”€â”€ ğŸ“„ README.md           # Este arquivo
```

## ğŸ› ï¸ Requisitos

Para rodar este projeto, vocÃª precisarÃ¡ das seguintes bibliotecas Python. Ã‰ altamente recomendado usar um ambiente virtual (`venv`).

* `tensorflow`
* `gradio`
* `numpy`
* `matplotlib`
* `pillow` (para processamento de imagem no `app.py`)

VocÃª pode instalar todas as dependÃªncias com o pip:

```bash
pip install -r requirements.txt       
```

## ğŸš€ Como Usar

O fluxo de trabalho Ã© simples: primeiro, treine o modelo; em seguida, execute a aplicaÃ§Ã£o web.

### Passo 1: Treinar o Modelo

Execute o script `treinar_modelo.py` no seu terminal. Este script irÃ¡:
1.  Baixar o dataset MNIST.
2.  Construir a arquitetura da CNN.
3.  Treinar o modelo por 10 Ã©pocas.
4.  Salvar o modelo treinado como `modelo_mnist.h5`.
5.  Salvar os grÃ¡ficos de performance como `graficos_treinamento.png`.

```bash
python treinar_modelo.py
```

### Passo 2: Executar a AplicaÃ§Ã£o Web

ApÃ³s o arquivo `modelo_mnist.h5` ser criado, execute o script `app.py`.

```bash
python app.py
```

### Passo 3: Testar no Navegador

O script `app.py` irÃ¡ iniciar um servidor local e fornecer um link (normalmente `http://127.0.0.1:7860`). Abra este link no seu navegador:

1.  Desenhe um dÃ­gito (de 0 a 9) na caixa "Desenhe aqui".
2.  Clique no botÃ£o **"Submit"**.
3.  O modelo farÃ¡ a previsÃ£o e mostrarÃ¡ os resultados (com as 3 maiores confianÃ§as) na caixa "PrevisÃ£o".
4.  Use o botÃ£o **"Clear"** para limpar o desenho e a previsÃ£o.

5.  ## ğŸ§  Arquitetura do Modelo (CNN)

Nosso modelo Ã© uma **Rede Neural Convolucional** (`Sequential`) construÃ­da com Keras. A arquitetura Ã© empilhada na seguinte ordem para processar as imagens 28x28:

1.  **`Conv2D`**: Camada "visual" inicial.
    * **Filtros:** 32
    * **FunÃ§Ã£o:** Detectar caracterÃ­sticas de baixo nÃ­vel (bordas, curvas).
2.  **`MaxPooling2D`**:
    * **FunÃ§Ã£o:** Reduzir o tamanho da imagem ("encolher"), mantendo apenas as caracterÃ­sticas mais fortes.
3.  **`Conv2D`**: Segunda camada "visual".
    * **Filtros:** 64
    * **FunÃ§Ã£o:** Usar as caracterÃ­sticas simples para detectar padrÃµes mais complexos (cÃ­rculos, linhas completas).
4.  **`MaxPooling2D`**:
    * **FunÃ§Ã£o:** Reduzir o tamanho novamente.
5.  **`Flatten`**:
    * **FunÃ§Ã£o:** "Achatar" o mapa 2D de caracterÃ­sticas em um vetor 1D (uma "lista") para alimentar o "cÃ©rebro" da rede.
6.  **`Dense`**: A principal camada "pensante".
    * **NeurÃ´nios:** 128
    * **FunÃ§Ã£o:** Analisar a combinaÃ§Ã£o de todos os padrÃµes encontrados para tomar uma decisÃ£o.
7.  **`Dropout`**:
    * **Taxa:** 0.5 (50%)
    * **FunÃ§Ã£o:** TÃ©cnica de regularizaÃ§Ã£o para prevenir *overfitting* (evitar que o modelo "decore" os dados).
8.  **`Dense` (Camada de SaÃ­da)**:
    * **NeurÃ´nios:** 10
    * **FunÃ§Ã£o:** Classificar a imagem em um dos 10 dÃ­gitos (0-9) usando `softmax` para gerar probabilidades.

**Total de ParÃ¢metros TreinÃ¡veis:** 225.034

## ğŸ“Š Dataset: MNIST (Treino e Teste)

Para treinar nossa rede, utilizamos o famoso dataset **MNIST**.

* **Tamanho das Imagens:** Todas as imagens sÃ£o em escala de cinza e padronizadas no tamanho de **28x28 pixels**.
* **Total de Amostras:** O dataset completo contÃ©m **70.000 imagens** no total.
* **DivisÃ£o dos Dados:** O Keras jÃ¡ nos entrega o dataset prÃ©-dividido em dois conjuntos distintos que nÃ£o se sobrepÃµem:
    * **Conjunto de Treinamento (`x_train`): 60.000 imagens (~85.7%)**
        * **Uso:** Material que o modelo "estuda" durante o `model.fit()`.
    * **Conjunto de Teste (`x_test`): 10.000 imagens (~14.3%)**
        * **Uso:** Passado para o `validation_data`. O modelo *nunca* aprende com essas imagens; elas sÃ£o usadas apenas como uma "prova final" ao fim de cada Ã©poca para garantir que o modelo estÃ¡ generalizando e nÃ£o apenas decorando.

### ğŸ‘¨â€ğŸ’» Integrantes do Grupo

* **Gabriel Bianconi** (RA: 20.00822-8)
* **Carlos Alberto Matias da Costa** (RA: 20.01308-6)
* **Bruno Fevereiro** (RA: 20.02194-0)
